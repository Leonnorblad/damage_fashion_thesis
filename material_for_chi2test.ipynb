{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **To perform the $\\chi^2$ test. TP, FP and FN frequencies are computed from validation data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "from collections import Counter\n",
    "\n",
    "def load_model(MODEL_NAME):\n",
    "    # Load the trained model\n",
    "    model = get_object_detection_model(num_classes=4)\n",
    "    # Load best version of model (lowest val loss)\n",
    "    model.load_state_dict(torch.load(f\"runs/{MODEL_NAME}/best.pth\"))\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model(\"202404211431_FasterRCNN_960\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data has 1000 samples.\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = r'./fashion_v1/yolo'\n",
    "CLASSES = ['bg', 'Hole', 'Stain', 'TUD']\n",
    "IMG_WIDTH = 1280\n",
    "IMG_HEIGHT = 720\n",
    "\n",
    "val_dataset = FashionDataset(\n",
    "    data_folder=DATA_FOLDER,\n",
    "    split='val',\n",
    "    width=IMG_WIDTH, height=IMG_HEIGHT,\n",
    "    transform = A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']}))\n",
    "\n",
    "print(f\"Validation data has {len(val_dataset)} sample{'s' if len(val_dataset)>1 else ''}.\")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=4, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.utils.collate_fn)\n",
    "\n",
    "def transform_target(dict_):\n",
    "    res = dict(\n",
    "        boxes=dict_['boxes'].detach().cpu().numpy(),\n",
    "        labels=dict_['labels'].detach().cpu().numpy()\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = ValidationMetric(model, val_loader, device)\n",
    "gt = met.get_ground_truth()\n",
    "gt = [transform_target(target) for target in gt]\n",
    "preds = met.get_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter predictions from thresholds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = copy.copy(preds)\n",
    "predictions = [apply_nms(pred, iou_thresh=0.4) for pred in predictions]\n",
    "predictions = [apply_threshold(pred, threshold=0.55) for pred in predictions]\n",
    "predictions = [transform_target(p) for p in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find TP, FP, FN for the diffrent classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = calculate_tp_fp_fn(predictions, gt, iou_threshold=0.25, type=\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are encoded as:\n",
    "- 1 = hole\n",
    "- 2 = stain\n",
    "- 3 = TUD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 6, 2: 31, 3: 54}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tp)\n",
    "sum(tp.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 15, 2: 314, 3: 25}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fp)\n",
    "sum(fp.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 11, 2: 72, 3: 82}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fn)\n",
    "sum(fn.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the number of predictions and gt march, ensuring the extraction worked correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 445 predictions. There should be 445 predictions, ok? True\n",
      "There are 256 ground truth. There should be 256 ground truth, ok? True\n"
     ]
    }
   ],
   "source": [
    "# Check that the number of TP, FP and FN are correct\n",
    "print(f\"There are {(sum(tp.values())+sum(fp.values()))} predictions. There should be {sum(len(pred['labels']) for pred in predictions)} predictions, ok? {sum(tp.values())+sum(fp.values()) == sum(len(pred['labels']) for pred in predictions)}\")\n",
    "print(f\"There are {(sum(tp.values())+sum(fn.values()))} ground truth. There should be {sum(len(gt['labels']) for gt in gt)} ground truth, ok? {sum(tp.values())+sum(fn.values()) == sum(len(gt['labels']) for gt in gt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find TP, FP, FN for the diffrent sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = calculate_tp_fp_fn(predictions, gt, iou_threshold=0.25, type=\"size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'small': 75, 'medium': 13, 'large': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tp)\n",
    "sum(tp.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'small': 179, 'medium': 120, 'large': 55}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fp)\n",
    "sum(fp.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'small': 128, 'medium': 26, 'large': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fn)\n",
    "sum(fn.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the number of predictions and gt march, ensuring the extraction worked correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 445 predictions. There should be 445 predictions, ok? True\n",
      "There are 256 ground truth. There should be 256 ground truth, ok? True\n"
     ]
    }
   ],
   "source": [
    "# Check that the number of TP, FP and FN are correct\n",
    "print(f\"There are {(sum(tp.values())+sum(fp.values()))} predictions. There should be {sum(len(pred['labels']) for pred in predictions)} predictions, ok? {sum(tp.values())+sum(fp.values()) == sum(len(pred['labels']) for pred in predictions)}\")\n",
    "print(f\"There are {(sum(tp.values())+sum(fn.values()))} ground truth. There should be {sum(len(gt['labels']) for gt in gt)} ground truth, ok? {sum(tp.values())+sum(fn.values()) == sum(len(gt['labels']) for gt in gt)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasterRcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
